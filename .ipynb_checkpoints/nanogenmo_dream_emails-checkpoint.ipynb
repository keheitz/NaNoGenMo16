{
 "metadata": {
  "name": "",
  "signature": "sha256:3e12bf5033a7461da40e0f363687437f8e792cf807797e5556d1262c9d109e51"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Text Collection"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Prerequisites"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#format for user agent: <platform>:<app ID>:<version string> (by /u/<reddit username>)\n",
      "my_user_agent = \"my user agent\"\n",
      "#OAuth2 instructions for obtaining client id and secret available here: https://github.com/reddit/reddit/wiki/OAuth2\n",
      "my_client_id = \"my client ID\"\n",
      "my_client_secret = \"my client secret\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get Reddit Instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import praw\n",
      "\n",
      "#todo - delete before pushing\n",
      "my_user_agent = \"Python:NaNoGenMo16:1.0 (by /u/MissMushkila)\"\n",
      "my_client_id = \"W5_b0b-0uk4OpA\"\n",
      "my_client_secret = \"R9YUtfYe2PsN8okcdM07ozdHlnk\"\n",
      "\n",
      "#read-only instance\n",
      "reddit = praw.Reddit(user_agent=my_user_agent,\n",
      "                     client_id=my_client_id,\n",
      "                     client_secret=my_client_secret)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Collect text from dreams subreddit"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_hot_posts(subreddit, num):\n",
      "    text = \"\"\n",
      "    for submission in reddit.subreddit(subreddit).hot(limit=num):\n",
      "        text += submission.selftext\n",
      "    return text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_random_post(subreddit):\n",
      "    submission = reddit.subreddit(subreddit).random()\n",
      "    return submission.selftext"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_posts_to_file(subreddit, quantity, filename):\n",
      "    for x in range(0,quantity):\n",
      "        text = get_random_post(subreddit).encode('utf-8')\n",
      "        with open(filename,'a') as f: # 'a' parameter indicates we want to append rather than overwrite the file\n",
      "            f.write(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_posts_to_file('dreams', 5000, \"dreamtext\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 113
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Text parsing/cleanup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#NLTK is a leading platform for building Python programs to work with human language data.\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tokenize text into sentences useing nltk\n",
      "nltk.download('punkt')\n",
      "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package punkt to\n",
        "[nltk_data]     C:\\Users\\Kelly\\AppData\\Roaming\\nltk_data...\n",
        "[nltk_data]   Package punkt is already up-to-date!\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#try to remove meta-dream sentences, e.g. \"in my dream I was...\" \"before I woke up\"\n",
      "substring_list = ['dream', 'dreams', 'wake', 'woke', 'sleep', 'sleeping', 'nightmare']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def strip_dream_sent(text):\n",
      "    output = \"\"\n",
      "    for sent in sent_detector.tokenize(text):\n",
      "        if any(substring in sent for substring in substring_list):\n",
      "            continue;\n",
      "        else:\n",
      "            output += \" \"\n",
      "            output += sent\n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Generate Novel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import markovify\n",
      "import random\n",
      "import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_output_text(filename):\n",
      "    with open(filename) as f:\n",
      "        text = f.read()\n",
      "    return text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_text = get_output_text(\"dreamtext\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_paragraph(clean_text):\n",
      "    # Build the model.\n",
      "    text_model = markovify.Text(clean_text)\n",
      "    num_sent = random.randint(5,25)\n",
      "\n",
      "    paragraph = \"\"\n",
      "\n",
      "    # Print varying number of  randomly-generated sentences\n",
      "    for i in range(num_sent):\n",
      "        paragraph += \" \" \n",
      "        paragraph += text_model.make_sentence()\n",
      "\n",
      "    return paragraph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#see output for randomly generated paragraph (te)\n",
      "print strip_dream_sent(generate_paragraph(output_text).decode('utf-8'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " She didn\u2019t look at their faces. WHAT?! *I had interrupted.* All three turned to me when I normally go to find out what happened next. I woke up in fear thinking I was worried about that over the campus in Google Earth. Made it to all just a nightmare, but I thought nothing of it in the back. The more we watched, the more cracks the more it hurts. Seattle had just taken office as the kids to kill me, to escape it and I'm just slowly getting over after four years. And he told me that the store with my mother and at this point?So I normally don't remember it. But I did not have been on my back, the door handle, I felt happy but uneasy during this. I coughed it up and the cat people escaped. We almost fell over the scene, sobbing, stunned silent. It's significant to me when I wake up feeling like when you're normally dreaming. Eventually I managed to wake up from a resaraunt into a not so good part of the class. He came back for the ring I wanted to have different genders and ages sitting around me. I saw my bones. He was bright and young, he wasn't sick and he was the rear left one for some cocaine to give us the new president. Once she had pink hair, and my friend Eric's mom was dressed in black.\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get random date in past\n",
      "def get_start_date():\n",
      "    daysintopast = random.randint(1000,15000)\n",
      "    startdate = datetime.datetime.now() - datetime.timedelta(days=daysintopast)\n",
      "    return startdate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#we want the diary to progress not every day, but have an entry every few days - method to get next diary entry date\n",
      "def get_next_date(currentdate):\n",
      "    daysadd = random.randint(1,5)\n",
      "    diarydate = currentdate + datetime.timedelta(days=daysadd)\n",
      "    return diarydate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#calls date and text generation methods to write to a file named according to the parameter novel_name\n",
      "#because we pulled the data from reddit posts, need to decode from utf-8 to ascii for use with nltk (tokenizing and strippping sentences)\n",
      "#re-encode to utf-8 before writing to the file\n",
      "#novel length indicates number of diary entries which average ~250 words\n",
      "def write_novel(novel_name, novel_length):\n",
      "    startdate = get_start_date()\n",
      "    entry = strip_dream_sent(generate_paragraph(output_text).decode('utf-8'))\n",
      "    with open(novel_name,'a') as f: \n",
      "            f.write(startdate.strftime(\"%B %d, %Y\") + '\\n')\n",
      "            f.write(entry.encode('utf-8') + '\\n\\n')\n",
      "    for x in range(novel_length):\n",
      "        startdate = get_next_date(startdate)\n",
      "        entry = strip_dream_sent(generate_paragraph(output_text).decode('utf-8'))\n",
      "        with open(novel_name,'a') as f: \n",
      "            f.write(startdate.strftime(\"%B %d, %Y\") + '\\n')\n",
      "            f.write(entry.encode('utf-8') + '\\n\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_novel(\"dream_diary\", 365)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}