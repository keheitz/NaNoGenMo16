{
 "metadata": {
  "name": "",
  "signature": "sha256:388c947f3f0a62464ab27268c38cd1aa0473eb5465e1bcc0bf72d747ca7ea5fe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Text Collection"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Prerequisites"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#format for user agent: <platform>:<app ID>:<version string> (by /u/<reddit username>)\n",
      "my_user_agent = \"my user agent\"\n",
      "#OAuth2 instructions for obtaining client id and secret available here: https://github.com/reddit/reddit/wiki/OAuth2\n",
      "my_client_id = \"my client ID\"\n",
      "my_client_secret = \"my client secret\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Get Reddit Instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import praw\n",
      "\n",
      "#todo - delete before pushing\n",
      "my_user_agent = \"Python:NaNoGenMo16:1.0 (by /u/MissMushkila)\"\n",
      "my_client_id = \"W5_b0b-0uk4OpA\"\n",
      "my_client_secret = \"R9YUtfYe2PsN8okcdM07ozdHlnk\"\n",
      "\n",
      "#read-only instance\n",
      "reddit = praw.Reddit(user_agent=my_user_agent,\n",
      "                     client_id=my_client_id,\n",
      "                     client_secret=my_client_secret)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Collect text from dreams subreddit"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_hot_posts(subreddit, num):\n",
      "    text = \"\"\n",
      "    for submission in reddit.subreddit(subreddit).hot(limit=num):\n",
      "        text += submission.selftext\n",
      "    return text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_random_post(subreddit):\n",
      "    submission = reddit.subreddit(subreddit).random()\n",
      "    return submission.selftext"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_posts_to_file(subreddit, quantity, filename):\n",
      "    for x in range(0,quantity):\n",
      "        text = get_random_post(subreddit).encode('utf-8')\n",
      "        with open(filename,'a') as f: # 'a' parameter indicates we want to append rather than overwrite the file\n",
      "            f.write(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_posts_to_file('dreams', 5000, \"dreamtext\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Text parsing/cleanup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#NLTK is a leading platform for building Python programs to work with human language data.\n",
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tokenize text into sentences useing nltk\n",
      "nltk.download('punkt')\n",
      "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#try to remove meta-dream sentences, e.g. \"in my dream I was...\" \"before I woke up\"\n",
      "substring_list = ['dream', 'dreams', 'wake', 'woke', 'sleep', 'sleeping', 'nightmare']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def strip_dream_sent(text):\n",
      "    output = \"\"\n",
      "    for sent in sent_detector.tokenize(text):\n",
      "        if any(substring in sent for substring in substring_list):\n",
      "            continue;\n",
      "        else:\n",
      "            output += \" \"\n",
      "            output += sent\n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_output_text(filename):\n",
      "    with open(filename) as f:\n",
      "        text = f.read()\n",
      "    return text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_text = get_output_text(\"dreamtext\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Generate Novel"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import markovify\n",
      "import random\n",
      "import datetime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_paragraph(clean_text):\n",
      "    # Build the model.\n",
      "    text_model = markovify.Text(clean_text)\n",
      "    num_sent = random.randint(5,25)\n",
      "\n",
      "    paragraph = \"\"\n",
      "\n",
      "    # Print varying number of  randomly-generated sentences\n",
      "    for i in range(num_sent):\n",
      "        paragraph += \" \" \n",
      "        paragraph += text_model.make_sentence()\n",
      "\n",
      "    return paragraph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#see output for randomly generated paragraph (testing)\n",
      "print strip_dream_sent(generate_paragraph(output_text).decode('utf-8'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get random date in past\n",
      "def get_start_date():\n",
      "    daysintopast = random.randint(1000,15000)\n",
      "    startdate = datetime.datetime.now() - datetime.timedelta(days=daysintopast)\n",
      "    return startdate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#we want the diary to progress not every day, but have an entry every few days - method to get next diary entry date\n",
      "def get_next_date(currentdate):\n",
      "    daysadd = random.randint(1,5)\n",
      "    diarydate = currentdate + datetime.timedelta(days=daysadd)\n",
      "    return diarydate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#calls date and text generation methods to write to a file named according to the parameter novel_name\n",
      "#because we pulled the data from reddit posts, need to decode from utf-8 to ascii for use with nltk (tokenizing and strippping sentences)\n",
      "#re-encode to utf-8 before writing to the file\n",
      "#novel length indicates number of diary entries which average ~250 words\n",
      "def write_novel(novel_name, novel_length):\n",
      "    startdate = get_start_date()\n",
      "    entry = strip_dream_sent(generate_paragraph(output_text).decode('utf-8'))\n",
      "    with open(novel_name,'a') as f: \n",
      "            f.write(startdate.strftime(\"%B %d, %Y\") + '\\n')\n",
      "            f.write(entry.encode('utf-8') + '\\n\\n')\n",
      "    for x in range(novel_length):\n",
      "        startdate = get_next_date(startdate)\n",
      "        entry = strip_dream_sent(generate_paragraph(output_text).decode('utf-8'))\n",
      "        with open(novel_name,'a') as f: \n",
      "            f.write(startdate.strftime(\"%B %d, %Y\") + '\\n')\n",
      "            f.write(entry.encode('utf-8') + '\\n\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_novel(\"horror-diary\", 365)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}